{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T07:57:31.828157300Z",
     "start_time": "2023-10-04T07:57:27.935910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading logs by lines:: 100%|██████████| 165435/165435 [00:02<00:00, 78832.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"HTTPS\"' '\"udp/443\"' '\"tcp/5228\"' '\"tcp/8883\"' '\"udp/21116\"' '\"DNS\"'\n",
      "  '\"HTTP\"' '\"tcp/5223\"' '\"PING\"']\n",
      " [48352 3498 1323 1151 695 643 563 102 39]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def log_reader(log_name):\n",
    "    \"\"\"\n",
    "    逐行读取日志，分割并提取，最后保存为 pandas dataframe\n",
    "    \"\"\"\n",
    "    with open(log_name, 'r', encoding='cp1252') as file:\n",
    "        # Get the total number of lines in the file\n",
    "        total_lines = sum(1 for _ in file)\n",
    "\n",
    "    with open(log_name, 'r', encoding='cp1252') as file:\n",
    "        split_results = []\n",
    "        # for line in file:\n",
    "        for line in tqdm(file, total=total_lines, desc=\"Reading logs by lines:\"):\n",
    "            words = line.split()[4:]\n",
    "            word_pair_dict = {}\n",
    "            for pairs in words:\n",
    "                try:\n",
    "                    ls_pairs = pairs.split(\"=\")\n",
    "                    word_pair_dict[ls_pairs[0]] = ls_pairs[1]\n",
    "                except IndexError:\n",
    "                    # ls_pairs = pairs.split(\"=\")\n",
    "                    # word_pair_dict[ls_pairs[0]] = \"\"\n",
    "                    pass\n",
    "            split_results.append(word_pair_dict)\n",
    "\n",
    "    results_df = pd.DataFrame(split_results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def count_column(df_name, col_name):\n",
    "    \"\"\"\n",
    "    根据列名分组，分组后计数，计数后进行降序排序\n",
    "    \"\"\"\n",
    "    count_col_name = col_name + \"计数\"\n",
    "    col_counts_df = df_name.groupby(col_name).size().reset_index(name=count_col_name)\n",
    "    sorted_df = col_counts_df.sort_values(by=count_col_name, ascending=False)\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "def select_by_value(df_name, col_name, col_value):\n",
    "    filter_df = df_name.loc[df_name[col_name] == col_value]\n",
    "    return filter_df\n",
    "\n",
    "\n",
    "def create_np(df_name, col_name):\n",
    "    df_col_count = count_column(df_name, col_name).head(20)\n",
    "    columns = df_col_count.columns.tolist()\n",
    "    df_col_count_np = df_col_count.to_numpy()\n",
    "#     df_col_count_np = [columns] + df_col_count_np.tolist()\n",
    "    return columns, np.transpose(df_col_count_np)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    the_log_short = \"message_179.170.130.210.bn.2iij.net_20230930.log\"\n",
    "    # the_log_long = \"message_179.170.130.210.bn.2iij.net_20231002.log\"\n",
    "    log_df = log_reader(the_log_short)\n",
    "    select_df = select_by_value(log_df, 'logid', log_df.iloc[0]['logid']) # logid = \"13\"\n",
    "    np_cols, array_2 = create_np(select_df, 'service')\n",
    "    print(array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7fcb953306c37f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
